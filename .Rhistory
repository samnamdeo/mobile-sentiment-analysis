axis.text.x = element_text(angle=16, vjust=0, size=8))
ggplotly(ep)
ep <- plotdat %>%
ggplot(aes(x = score, fill = name)) +geom_histogram(binwidth = 1) +
scale_fill_manual(values = c("#0067F7","#7B00F7", "#7CF700", "#F70000","#7CF800")) +
theme_classic(base_size = 12) +scale_x_continuous(name = "Sentiment Score") +
scale_y_continuous(name = "Text count of tweets") +ggtitle("Super Mobiles Twitter Sentiment: 2016")+
theme(axis.title.y = element_text(face="bold", colour="#000000", size=10),axis.title.x = element_text(face="bold", colour="#000000", size=8),
axis.text.x = element_text(angle=16, vjust=0, size=8))
ggplotly(ep)
ep <- plotdat %>%
ggplot(aes(x = score, fill = name)) +geom_histogram(binwidth = 1) +
scale_fill_manual(values = rainbow(20)) +
theme_classic(base_size = 12) +scale_x_continuous(name = "Sentiment Score") +
scale_y_continuous(name = "Text count of tweets") +ggtitle("Super Mobiles Twitter Sentiment: 2016")+
theme(axis.title.y = element_text(face="bold", colour="#000000", size=10),axis.title.x = element_text(face="bold", colour="#000000", size=8),
axis.text.x = element_text(angle=16, vjust=0, size=8))
ggplotly(ep)
ep <- plotdat %>%
ggplot(aes(x = score, fill = name)) +geom_histogram(binwidth = 1) +
scale_fill_manual(values = rainbow(5)) +
theme_classic(base_size = 12) +scale_x_continuous(name = "Sentiment Score") +
scale_y_continuous(name = "Text count of tweets") +ggtitle("Super Mobiles Twitter Sentiment: 2016")+
theme(axis.title.y = element_text(face="bold", colour="#000000", size=10),axis.title.x = element_text(face="bold", colour="#000000", size=8),
axis.text.x = element_text(angle=16, vjust=0, size=8))
ggplotly(ep)
clean.text = function(x)
{
# tolower
x = tolower(x)
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
return(x)
}
samsung_clean = clean.text(feed_samsung)
clean.text = function(x)
{
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
# tolower
x = tolower(x)
return(x)
}
samsung_clean = clean.text(feed_samsung)
iphone_clean = clean.text(feed_iphone)
motorola_clean = clean.text(feed_motorola)
lenovo_clean = clean.text(feed_lenovo)
micromax_clean=clean.text(feed_micromax)
samsung = paste(samsung_clean, collapse=" ")
iphone = paste(iphone_clean, collapse=" ")
motorola = paste(motorola_clean, collapse=" ")
lenovo = paste(lenovo_clean, collapse=" ")
micromax=paste(micromax_clean, collapse =" ")
all = c(samsung, iphone, motorola, lenovo,micromax)
all = removeWords(all,
c(stopwords("english"), "samsung", "iphone", "motorola", "micromax","lenovo"))
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
clean.text = function(x)
{
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
# tolower
x = tolower(x)
return(x)
}
samsung_clean = clean.text(feed_samsung)
iphone_clean = clean.text(feed_iphone)
motorola_clean = clean.text(feed_motorola)
lenovo_clean = clean.text(feed_lenovo)
micromax_clean=clean.text(feed_micromax)
samsung = paste(samsung_clean, collapse=" ")
iphone = paste(iphone_clean, collapse=" ")
motorola = paste(motorola_clean, collapse=" ")
lenovo = paste(lenovo_clean, collapse=" ")
micromax=paste(micromax_clean, collapse =" ")
all = c(samsung, iphone, motorola, lenovo,micromax)
all = tm_map(all,removeWords,
c(stopwords("english"), "samsung", "iphone", "motorola", "micromax","lenovo"))
all = removeWords(all,removeWords,
c(stopwords("english"), "samsung", "iphone", "motorola", "micromax","lenovo"))
corpus = Corpus(VectorSource(all))
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = c("samsunf", "iphone", "motorola", "micromax","lenovo")
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1.5, max.words=500)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1.5, max.words=500)
warnings()
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1.5, max.words=300)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1.5, max.words=100)
colnames(tdm) = c("samsung", "iphone", "motorola", "micromax","lenovo")
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1.5, max.words=200)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=200)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=200)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=200)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=250)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=150)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=250)
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
clean.text = function(x)
{
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
# tolower
x = tolower(x)
return(x)
}
samsung_clean = clean.text(feed_samsung)
iphone_clean = clean.text(feed_iphone)
motorola_clean = clean.text(feed_motorola)
lenovo_clean = clean.text(feed_lenovo)
micromax_clean=clean.text(feed_micromax)
samsung = paste(samsung_clean, collapse=" ")
iphone = paste(iphone_clean, collapse=" ")
motorola = paste(motorola_clean, collapse=" ")
lenovo = paste(lenovo_clean, collapse=" ")
micromax=paste(micromax_clean, collapse =" ")
all = c(samsung, iphone, motorola, lenovo,micromax)
all = removeWords(all,removeWords,
c(stopwords("english"), "samsung", "iphone", "motorola", "micromax","lenovo"))
corpus = Corpus(VectorSource(all))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
corpus <- tm_map(corpus, toSpace, "/")
corpus <- tm_map(corpus, toSpace, "@")
corpus <- tm_map(corpus, toSpace, "\\|")
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, removeWords, c("blabla1", "blabla2","samsung","lenovo","iphone","motorola","micromax"))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = c("samsung", "iphone", "motorola", "micromax","lenovo")
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=250)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=500)
corpus <- tm_map(corpus, removeWords, c("blabla1", "blabla2","samsung","lenovo","iphone","motorola","micromax","moto"))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
tdm = TermDocumentMatrix(corpus)
tdm = as.matrix(tdm)
colnames(tdm) = c("samsung", "iphone", "motorola", "micromax","lenovo")
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=500)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=100)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=200)
comparison.cloud(tdm, random.order=FALSE,
colors = rainbow(14),
title.size=1, max.words=300)
comparison.cloud(tdm, random.order=TRUE,
colors = rainbow(14),
title.size=1, max.words=300)
comparison.cloud(tdm, random.order=TRUE,
colors = rainbow(14),
title.size=1, max.words=100)
comparison.cloud(tdm, random.order=TRUE,
colors = rainbow(14),
title.size=1, max.words=200)
comparison.cloud(tdm, random.order=TRUE,
colors = rainbow(14),
title.size=1, max.words=400)
comparison.cloud(tdm, random.order=TRUE,
colors = rainbow(14),
title.size=1, max.words=500)
getwd()
ep <- plotdat %>%
ggplot(aes(x = score, fill = name)) +geom_histogram(binwidth = 1) +
scale_fill_manual(values = rainbow(5)) +
theme_classic(base_size = 12) +scale_x_continuous(name = "Sentiment Score") +
scale_y_continuous(name = "Text count of tweets") +ggtitle("Super Mobiles Twitter Sentiment: 2016")+
theme(axis.title.y = element_text(face="bold", colour="#000000", size=10),axis.title.x = element_text(face="bold", colour="#000000", size=8),
axis.text.x = element_text(angle=16, vjust=0, size=8))
getwd()
getwd()
score.sentiment <- function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, good_text, bad_text) {
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
samsung <- score.sentiment(feed_samsung, good_text, bad_text, .progress='text')
samsung$name <- 'samsung'
iphone <- score.sentiment(feed_iphone, good_text, bad_text, .progress='text')
iphone$name <- 'iphone'
motorola <- score.sentiment(feed_motorola, good_text, bad_text, .progress='text')
motorola$name <- 'motorola'
lenovo <- score.sentiment(feed_lenovo, good_text, bad_text, .progress='text')
lenovo$name <- 'lenovo'
micromax<-score.sentiment(feed_micromax,good_text,bad_text, .progress='text')
micromax$name<-'micromax'
plotdat <- rbind(samsung, motorola, iphone, lenovo, micromax)
plotdat <- plotdat[c("name", "score")]
plotdat <- plotdat[!plotdat$score == 0, ]
plotdat <- plotdat[!plotdat$score > 3, ]
plotdat <- plotdat[!plotdat$score < (-3), ]
qplot(factor(score), data=plotdat, geom="bar",fill=factor(name),xlab = "Sentiment Score")
library(plyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(RColorBrewer)
library(twitteR)
qplot(factor(score), data=plotdat, geom="bar",fill=factor(name),xlab = "Sentiment Score")
ep <- plotdat %>%
ggplot(aes(x = score, fill = name)) +geom_histogram(binwidth = 1) +
scale_fill_manual(values = rainbow(5)) +
theme_classic(base_size = 12) +scale_x_continuous(name = "Sentiment Score") +
scale_y_continuous(name = "Text count of tweets") +ggtitle("Super Mobiles Twitter Sentiment: 2017")+
theme(axis.title.y = element_text(face="bold", colour="#000000", size=10),axis.title.x = element_text(face="bold", colour="#000000", size=8),
axis.text.x = element_text(angle=16, vjust=0, size=8))
ggplotly(ep)
library(plotly)
ggplotly(ep)
score.sentiment <- function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, good_text, bad_text)
{
sentence = gsub('[[:punct:]]', '', sentence)
sentence=gsub("(RT|via)((?:\\b\\W*@\\w+)+)","",sentence)
sentence =gsub("@\\w+",'',sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub("[[:digit:]]",'',sentence)
sentence = gsub('\\d+', '', sentence)
sentence = gsub("http\\w+",'',sentence)
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
summary(plotdat)
sentimentscore<-plotdat$score
hist(sentimentscore,main="histogram:india Smartcities",col = rainbow(9))
qplot(factor(score), data=plotdat, geom = "bar",xlab = "Sentiment Score",main="barplot:India Smartcities")
ep <- plotdat %>% ggplot(aes(x = score,)) +geom_histogram(binwidth = 1) +
scale_fill_manual(values = c("#0067F7","#7B00F7", "#7CF700", "#F70000")) +
theme_classic(base_size = 12) +scale_x_continuous(name = "Sentiment Score") +
scale_y_continuous(name = "Text count of tweets") +ggtitle("Smartcity India")+
theme(axis.title.y = element_text(face="bold", colour="#000000", size=10),axis.title.x = element_text(face="bold", colour="#000000", size=8),
axis.text.x = element_text(angle=16, vjust=0, size=8))
ggplotly(ep)
library(tm)
library(wordcloud)
View(plotdat)
combine2=read.csv("H:/New folder (3)/New folder/combine.csv")
clean=Corpus(VectorSource(combine2),readerControl = list(language="eng"))
inspect(clean)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(clean, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
docs <- tm_map(docs, toSpace,"https*")
docs <- tm_map(docs, toSpace,"tco*")
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removeWords, stopwords("english"))
myStopwords <- c(stopwords('english'),"r", "big","uuuu","uucu","uuf","uufu","uufuf","uufufue","androida","blooddonorsin","clienta","ciudades",
"con","conn","cop","des","eampit","eduaubdedubu","eduaubdedububd","eduaubdedubueduaubdedubuuuuueuuudrkumarvis","eec",
"engb","espa침a","euw","evankirstel","href","hrefhttpsdoordacom","htt","http","ipada","iphonea","ipfconline","iwaterbarcelona",
"los", "las","mer","nov","otvnews","ppchaudharymos","ravi","relnofollowaaretweeta","relnofollowapp","relnofollowbuffera","relnofollowfacebooka",
"relnofollowgrabinboxa","relnofollowhootsuitea","relnofollowifttta","relnofollowmobile","relnofollowpaperlia","relnofollowscbotbackenda",
"relnofollowtweetdecka","relnofollowwiocitiesa","relnofollowclickkla","relnofollowfacebooka","relnofollowhootsuitea","uuuufufu","vikezmedia",
"relnofollowinstagrama","relnofollowtopicly","relnofollowtwitter","revoluci칩","rfyouthsports","rsprasad","rfyouthsports","scewc","vijayshekhar",
"shankar","sunnybhullar","ttot","ububuuc","ucuc","ucuu","uduu","uufudueu","uufue","uuu","uufudueu","uufue","uuuu","uufuuu","uuue","wiomaxmd","ueubuu",
"ueuu","ueuuuduueuuf","ufu","ufuu","uidai","una","uub","uubuf","uudufue","uueu","uueucuduf","yfnvillage","yfnmwc","available","via","tco","ufu","uuu")
docs <- tm_map(docs, removeWords, myStopwords)
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeURL)
library(SnowballC)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
dtm
(freq.terms <- findFreqTerms(dtm, lowfreq = 15))
term.freq <- rowSums(as.matrix(dtm))
term.freq <- subset(term.freq, term.freq >= 500)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity")+geom_point() + xlab("Terms") + ylab("Count")+ coord_flip()
m <- as.matrix(dtm)
m
v <- sort(rowSums(m),decreasing=TRUE)
v
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=rainbow(6))
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=100, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(10, "Dark2"))
myStopwords <- c(stopwords('english'),"r", "big","uuuu","uucu","uuf","uufu","uufuf","uufufue","androida","blooddonorsin","clienta","ciudades",
"con","conn","cop","des","eampit","eduaubdedubu","eduaubdedububd","eduaubdedubueduaubdedubuuuuueuuudrkumarvis","eec",
"engb","espa침a","euw","evankirstel","href","hrefhttpsdoordacom","htt","http","ipada","iphonea","ipfconline","iwaterbarcelona",
"los", "las","mer","nov","otvnews","ppchaudharymos","ravi","relnofollowaaretweeta","relnofollowapp","relnofollowbuffera","relnofollowfacebooka",
"relnofollowgrabinboxa","relnofollowhootsuitea","relnofollowifttta","relnofollowmobile","relnofollowpaperlia","relnofollowscbotbackenda",
"relnofollowtweetdecka","relnofollowwiocitiesa","relnofollowclickkla","relnofollowfacebooka","relnofollowhootsuitea","uuuufufu","vikezmedia",
"relnofollowinstagrama","relnofollowtopicly","relnofollowtwitter","revoluci칩","rfyouthsports","rsprasad","rfyouthsports","scewc","vijayshekhar",
"shankar","sunnybhullar","ttot","ububuuc","ucuc","ucuu","uduu","uufudueu","uufue","uuu","uufudueu","uufue","uuuu","uufuuu","uuue","wiomaxmd","ueubuu",
"ueuu","ueuuuduueuuf","ufu","ufuu","uidai","una","uub","uubuf","uudufue","uueu","uueucuduf","yfnvillage","yfnmwc","available","via","tco","ufu","uuu","yaywqpuynormaljpg","uufef",
"reInfollowtwitt","reInfollowwordpresscom","pbstwimgcom","profileimag","wwwgooglecom","rtampfollow")
docs <- tm_map(docs, removeWords, myStopwords)
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2"))
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeURL)
library(SnowballC)
docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
dtm
(freq.terms <- findFreqTerms(dtm, lowfreq = 15))
(freq.terms <- findFreqTerms(dtm, lowfreq = 150))
(freq.terms <- findFreqTerms(dtm, lowfreq = 150))
term.freq <- rowSums(as.matrix(dtm))
term.freq <- subset(term.freq, term.freq >= 500)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity")+geom_point() + xlab("Terms") + ylab("Count")+ coord_flip()
m <- as.matrix(dtm)
m
v <- sort(rowSums(m),decreasing=TRUE)
v
d <- data.frame(word = names(v),freq=v)
head(d, 10)
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=rainbow(6))
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=100, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(10, "Dark2"))
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=rainbow(14))
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=100, random.order=FALSE, rot.per=0.35,
colors=rainbow(14))
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=100, random.order=FALSE, rot.per=0.35,
colors=rainbow(7))
wordcloud(words = d$word, freq = d$freq, min.freq = 150,
max.words=100, random.order=FALSE, rot.per=0.35,
colors=rainbow(7))
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
max.words=100, random.order=TRUE, rot.per=0.35,
colors=brewer.pal(10, "Dark2"))
wordcloud(words = d$word, freq = d$freq,
max.words=100, random.order=TRUE,
colors=rainbow(7))
wordcloud(words = d$word, freq = d$freq,
max.words=100, random.order=TRUE,
colors=rainbow(14))
wordcloud(dtm,
max.words=500, random.order=TRUE,
colors=rainbow(14))
score.sentiment <- function(sentences, good_text, bad_text, .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences, function(sentence, good_text, bad_text)
{
sentence = gsub('[[:punct:]]', '', sentence)
sentence=gsub("(RT|via)((?:\\b\\W*@\\w+)+)","",sentence)
sentence =gsub("@\\w+",'',sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub("[[:digit:]]",'',sentence)
sentence = gsub('\\d+', '', sentence)
sentence = gsub("http\\w+",'',sentence)
sentence <- iconv(sentence, 'UTF-8', 'ASCII')
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)
pos.matches = match(words, good_text)
neg.matches = match(words, bad_text)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, good_text, bad_text, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
combine$text<-as.factor(combine$text)
combine$text<-as.factor(combine2$text)
combine2$text<-as.factor(combine2$text)
combine.scores=score.sentiment(combine2$text,good_text,bad_text, .progress = 'text')
plotdat <- combine.scores
library(ggplot2)
library(plotly)
summary(plotdat)
sentimentscore<-plotdat$score
hist(sentimentscore,main="histogram:india Smartcities",col = rainbow(9))
qplot(factor(score), data=plotdat, geom = "bar",xlab = "Sentiment Score",main="barplot:India Smartcities")
hist(sentimentscore,main="histogram:famous mobile products",col = rainbow(9))
